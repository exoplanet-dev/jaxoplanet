{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(transit)=\n",
    "\n",
    "# Transit Fitting\n",
    "\n",
    "Like `exoplanet`, `jaxoplanet` includes methods for computing the light curves of transiting exoplanets. In this tutorial, we introduce these methods and use it alongside the `NumPyro` probabilistic programming library to do some transit fitting. Parts of this tutorial will follow the [Transit Fitting tutorial](https://gallery.exoplanet.codes/tutorials/transit/) for the `exoplanet` package.\n",
    "\n",
    "```{note}\n",
    "This tutorial requires some [extra packages](about.ipynb) that are not included in the `jaxoplanet` dependencies.\n",
    "```\n",
    "\n",
    "## Setup\n",
    "\n",
    "We first setup the number of CPUs to use and enable the use of double-precision numbers with jax. We also import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpyro\n",
    "\n",
    "# For multi-core parallelism (useful when running multiple MCMC chains in parallel)\n",
    "numpyro.set_host_device_count(2)\n",
    "\n",
    "# For CPU (use \"gpu\" for GPU)\n",
    "numpyro.set_platform(\"cpu\")\n",
    "\n",
    "# For 64-bit precision since JAX defaults to 32-bit\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "\n",
    "Let's first compute a simple light curve.\n",
    "\n",
    "The light curve calculation requires an orbit object. We'll use [TransitOrbit](jaxoplanet.orbits.transit.TransitOrbit) (similar to [SimpleTransitOrbit](https://docs.exoplanet.codes/en/latest/user/api/#exoplanet.orbits.SimpleTransitOrbit) in the exoplanet package), which is an orbit parameterized by the observables of a transiting system: period, speed/duration, time of transit, impact parameter, and radius ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jaxoplanet.orbits import TransitOrbit\n",
    "from jaxoplanet.light_curves import limb_dark_light_curve\n",
    "\n",
    "orbit = TransitOrbit(\n",
    "    period=3.456, duration=0.12, time_transit=0.0, impact_param=0.0, radius_ratio=0.1\n",
    ")\n",
    "\n",
    "# Compute a limb-darkened light curve for this orbit\n",
    "time = np.linspace(-0.1, 0.1, 1000)\n",
    "u = [0.1, 0.06]  # Quadratic limb-darkening coefficients\n",
    "light_curve = limb_dark_light_curve(orbit, u)(time)\n",
    "\n",
    "# Plot the light curve\n",
    "plt.plot(time, light_curve)\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlim(time.min(), time.max())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit model in NumPyro\n",
    "\n",
    "We'll construct a transit model using `NumPyro` and fit to some simulated data. `NumPyro` is a probabilistic programming library (PPLs) like `PyMC` that allows us to succinctly build models and perform (gradient-based) inference with them. **NumPyro models must be written in JAX!**\n",
    "\n",
    "\n",
    "Let's start off by choosing the transit properties of our simulated data. These will be the \"true\" values that we would like to recover with our inference. \n",
    "<!-- To make our lives easier let's set the impact parameter $b$ to be 0.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate some data with Gaussian noise\n",
    "random = np.random.default_rng(42)\n",
    "PERIOD = random.uniform(2, 5)  # day\n",
    "T0 = PERIOD * random.uniform()  # day\n",
    "DURATION = 0.5  # day\n",
    "B = 0.5  # impact parameter\n",
    "ROR = 0.08  # planet radius / star radius\n",
    "U = np.array([0.1, 0.06])  # limb darkening coefficients\n",
    "yerr = 5e-4  # flux uncertainty\n",
    "time = np.arange(0, 17, 0.05)  # day\n",
    "\n",
    "\n",
    "orbit = TransitOrbit(\n",
    "    period=PERIOD, duration=DURATION, time_transit=T0, impact_param=B, radius_ratio=ROR\n",
    ")\n",
    "y_true = limb_dark_light_curve(orbit, U)(time)\n",
    "y = y_true + yerr * random.normal(size=len(time))\n",
    "\n",
    "# Let's see what the light curve looks like\n",
    "plt.plot(time, y, \".\", c=\"0.6\", label=\"data\")\n",
    "plt.plot(time, y_true, \"-k\", label=\"truth\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlim(time.min(), time.max())\n",
    "_ = plt.legend(loc=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "Let's define our numpyro model. The syntax for numpyro might be a bit unfamiliar, but here it is.\n",
    "We're sampling the period and duration in log space to constrain it to positive values, and we're also sampling the quadratic limb darkening coefficients using the custom distribution `QuadLDParams` in the `numpyro_ext` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro_ext\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def light_curve_model(time, params):\n",
    "    orbit = TransitOrbit(\n",
    "        period=params[\"period\"],\n",
    "        duration=params[\"duration\"],\n",
    "        time_transit=params[\"t0\"],\n",
    "        impact_param=params[\"b\"],\n",
    "        radius_ratio=params[\"r\"],\n",
    "    )\n",
    "    return limb_dark_light_curve(orbit, params[\"u\"])(time)\n",
    "\n",
    "\n",
    "def model(t, yerr, y=None):\n",
    "    # Priors for the parameters we're fitting for\n",
    "\n",
    "    # The time of reference transit\n",
    "    t0 = numpyro.sample(\"t0\", numpyro.distributions.Normal(T0, 1))\n",
    "\n",
    "    # The period\n",
    "    logP = numpyro.sample(\"logP\", numpyro.distributions.Normal(jnp.log(PERIOD), 0.1))\n",
    "    period = numpyro.deterministic(\"period\", jnp.exp(logP))\n",
    "\n",
    "    # The duration\n",
    "    logD = numpyro.sample(\"logD\", numpyro.distributions.Normal(jnp.log(DURATION), 0.1))\n",
    "    duration = numpyro.deterministic(\"duration\", jnp.exp(logD))\n",
    "\n",
    "    # The radius ratio\n",
    "    # logR = numpyro.sample(\"logR\", numpyro.distributions.Normal(jnp.log(ROR), 0.1))\n",
    "    r = numpyro.sample(\"r\", numpyro.distributions.Uniform(0.01, 0.2))\n",
    "    # r = numpyro.deterministic(\"r\", jnp.exp(logR))\n",
    "\n",
    "    # The impact parameter\n",
    "    # b = numpyro.sample(\"b\", numpyro.distributions.Uniform(0, 1.0))\n",
    "    _b = numpyro.sample(\"_b\", numpyro.distributions.Uniform(0, 1.0))\n",
    "    b = numpyro.deterministic(\"b\", _b * (1 + r))\n",
    "\n",
    "    # The limb darkening coefficients\n",
    "    u = numpyro.sample(\"u\", numpyro_ext.distributions.QuadLDParams())\n",
    "\n",
    "    # The orbit and light curve\n",
    "    y_pred = light_curve_model(\n",
    "        t, {\"period\": period, \"duration\": duration, \"t0\": t0, \"b\": b, \"r\": r, \"u\": u}\n",
    "    )\n",
    "\n",
    "    # Let's track the light curve\n",
    "    numpyro.deterministic(\"light_curve\", y_pred)\n",
    "\n",
    "    # The likelihood function assuming Gaussian uncertainty\n",
    "    numpyro.sample(\"obs\", numpyro.distributions.Normal(y_pred, yerr), obs=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the priors\n",
    "\n",
    "It can be a good idea to see whether the priors we defined are reasonable by sampling and plotting them. Let's do that now using the `numpyro.infer` submodule's `Predictive` functionality to draw some samples from the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "n_prior_samples = 3000\n",
    "prior_samples = numpyro.infer.Predictive(model, num_samples=n_prior_samples)(\n",
    "    jax.random.PRNGKey(0), time, yerr\n",
    ")\n",
    "\n",
    "# Let's make it into an arviz InferenceData object.\n",
    "# To do so we'll first need to reshape the samples to be of shape (chains, draws, *shape)\n",
    "converted_prior_samples = {\n",
    "    f\"{p}\": np.expand_dims(prior_samples[p], axis=0) for p in prior_samples\n",
    "}\n",
    "prior_samples_inf_data = az.from_dict(converted_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "# Plot the corner plot\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "_ = corner.corner(\n",
    "    prior_samples_inf_data,\n",
    "    fig=fig,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    truths=[T0, PERIOD, DURATION, ROR, B, U[0], U[1]],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 10},\n",
    "    label_kwargs={\"fontsize\": 10},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These priors seems sensible enough and the true values (blue lines) are within their bounds. Before we start sampling, let's find the maximum a posteriori (MAP) solution. This is a good starting point for the sampling we'll perform later and also a good check to see if things are working.\n",
    "We'll use the `optimize` function defined within the `numpyro_ext` package.\n",
    "\n",
    "We have a choice for the inital value of the optimization. Some potential options include:\n",
    "1. Manually setting them to a specific set of values. This approach might make sense for real data when it's a system that's been studied before and there's a good guess for the parameters. As an example, if we were fitting some follow-up ground-based transit data it might make sense to use the parameters from a Kepler/TESS discovery paper as the initial values.\n",
    "2. The median values of the priors. This might be a good idea when we don't have a good guess for the parameters. Similarly, we could also use the mean values of the priors.\n",
    "\n",
    "Let's do the former and set the initial values to the true values. \n",
    "<!-- Let's do the latter and set the initial values to the median values of the priors. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_param_method = \"true_values\"  # \"prior_median\" or \"true_values\"\n",
    "\n",
    "if init_param_method == \"prior_median\":\n",
    "    print(\"Starting from the prior medians\")\n",
    "    run_optim = numpyro_ext.optim.optimize(\n",
    "        model, init_strategy=numpyro.infer.init_to_median()\n",
    "    )\n",
    "elif init_param_method == \"true_values\":\n",
    "    print(\"Starting from the true values\")\n",
    "    init_params = {\n",
    "        \"t0\": T0,\n",
    "        \"logP\": jnp.log(PERIOD),\n",
    "        \"logD\": jnp.log(DURATION),\n",
    "        \"logR\": jnp.log(ROR),\n",
    "        \"_b\": B / (1 + ROR),\n",
    "        \"u\": U,\n",
    "    }\n",
    "    run_optim = numpyro_ext.optim.optimize(\n",
    "        model,\n",
    "        init_strategy=numpyro.infer.init_to_value(values=init_params),\n",
    "    )\n",
    "\n",
    "opt_params = run_optim(jax.random.PRNGKey(5), time, yerr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in opt_params.items():\n",
    "    if k in [\"light_curve\", \"obs\", \"_b\"]:\n",
    "        continue\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the MAP model against the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, y, \".\", c=\"0.7\", label=\"data\")\n",
    "plt.plot(time, y_true, \"-k\", label=\"truth\")\n",
    "plt.plot(time, opt_params[\"light_curve\"], \"--C0\", label=\"MAP model\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.legend(fontsize=10, loc=4)\n",
    "plt.xlim(time.min(), time.max())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Not surprisingly, the MAP model is  a good fit to the data.\n",
    "Let's use these MAP values as the initial values for our sampling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Let's sample from the posterior defined by this model and data. We'll use the No-U-Turn Sampler (NUTS) algorithm, which is a variant of the Hamiltonian Monte Carlo (HMC) algorithm that automatically tunes some of the sampling parameters.\n",
    "\n",
    "This cell takes about a minute to run on my laptop. Don't worry if it doesn't seem like anything is happening for a while at the beginning; compiling the code and running the first 100-200 iterations are the most computationally demanding and the subsequent sampling runs much faster!\n",
    "\n",
    "Below, we're setting the ``regularize_mass_matrix`` keyword to ``False``. This is because we realized that the default of setting it to ``True`` causes the sampling to be slower (roughly 4 times slower). We're investigating why but it seems (at least for this case) the posteriors are pretty much the same whether you regularize the mass matrix or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = numpyro.infer.MCMC(\n",
    "    numpyro.infer.NUTS(\n",
    "        model,\n",
    "        dense_mass=True,\n",
    "        regularize_mass_matrix=False,\n",
    "        init_strategy=numpyro.infer.init_to_value(values=opt_params),\n",
    "    ),\n",
    "    num_warmup=1000,\n",
    "    num_samples=2000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "sampler.run(jax.random.PRNGKey(1), time, yerr, y=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking our posterior samples\n",
    "\n",
    "We should check the convergence of our sampler. Determining whether a sampler has converged is not trivial and there is a lot of literature on the subject. Here we'll attempt to check for convergence by looking at the the Gelman-Rubin $\\hat{R}$ statistic and the bulk effective sample size (ESS) of each parameter. \n",
    "\n",
    "- The [$\\hat{R}$ statistic](https://bookdown.org/rdpeng/advstatcomp/monitoring-convergence.html) is a diagnostic of convergence based on the ratio of the variance between chains to the variance within chains. We would like for it to be close to 1.00 for each parameter. \n",
    "- The [ESS](https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html) is a measure of the number of independent samples in the chains and is inversely correlated with the autocorrelation in a chain. Larger estimates for the ESS are better as they indicate less autocorrelation in the chains.\n",
    "\n",
    "We can get both of these values using the `summary` function in the `Arviz` package. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = az.from_numpyro(sampler)\n",
    "samples = sampler.get_samples()\n",
    "az.summary(inf_data, var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ESS (`ess_bulk`) isn't great for some of the parameters, like the duration and the impact parameter $b$, but since the $\\hat{R}$ values are good let's just go ahead with these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's also a method to obtain similar results to `az.summary` but directly\n",
    "# as a method with the MCMC sampler. It also gives us the number of divergences.\n",
    "sampler.print_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a different view of the chains by making some trace plots. We can do this using the `plot_trace` function in the `Arviz` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_trace(\n",
    "    inf_data,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    backend_kwargs={\"constrained_layout\": True},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different line styles (not colors!) above indicate the different chains. There's two colors for $u$ since there are two limb-darkening coefficients (i.e., $u_1, u_2$).\n",
    "\n",
    "Let's now make a corner plot of the posterior samples to see the pairwise joint distributions of the parameters and see if there are any correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "_ = corner.corner(\n",
    "    inf_data,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    truths=[T0, PERIOD, DURATION, ROR, B, U[0], U[1]],\n",
    "    show_titles=True,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    title_kwargs={\"fontsize\": 10},\n",
    "    label_kwargs={\"fontsize\": 10},\n",
    "    title_fmt=\".4f\",\n",
    "    fig=fig,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue lines indicate the true values. All the true values are within 1-sigma of the marginalized posterior distributions, which is good!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase plots\n",
    "Let's make the phase plot that is commonly shown in exoplanet papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_params = {\n",
    "    \"t0\": np.median(samples[\"t0\"]),\n",
    "    \"period\": np.median(samples[\"period\"]),\n",
    "    \"duration\": np.median(samples[\"duration\"]),\n",
    "    \"r\": np.median(samples[\"r\"]),\n",
    "    \"b\": np.median(samples[\"b\"]),\n",
    "    \"u\": np.median(samples[\"u\"], axis=0),\n",
    "}\n",
    "\n",
    "\n",
    "y_model = light_curve_model(time, inferred_params)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the folded data\n",
    "t_fold = (\n",
    "    time - inferred_params[\"t0\"] + 0.5 * inferred_params[\"period\"]\n",
    ") % inferred_params[\"period\"] - 0.5 * inferred_params[\"period\"]\n",
    "ax.errorbar(t_fold, y, yerr=yerr, fmt=\".\", color=\"0.6\", label=\"data\", zorder=-100)\n",
    "\n",
    "# Plot the folded model\n",
    "inds = np.argsort(t_fold)\n",
    "ax.plot(t_fold[inds], y_model[inds], color=\"C0\", label=\"inferred model\")\n",
    "ax.set_xlim(inferred_params[\"duration\"] * jnp.array([-1, 1]) * 1.5)\n",
    "ax.set_xlabel(\"time since transit [days]\")\n",
    "ax.set_ylabel(\"relative flux\")\n",
    "ax.legend(loc=4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxoplanet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
