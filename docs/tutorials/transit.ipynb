{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(transit)=\n",
    "\n",
    "# Transit Fitting\n",
    "\n",
    "Like `exoplanet`, `jaxoplanet` includes methods for computing the light curves of transiting exoplanets. In this tutorial, we introduce these methods and use it alongside the `NumPyro` probabilistic programming library to do some transit fitting. Parts of this tutorial will follow the [Transit Fitting tutorial](https://gallery.exoplanet.codes/tutorials/transit/) for the `exoplanet` package.\n",
    "\n",
    "In addition to `jaxoplanet` (and [`NumPy`](https://numpy.org/), [`Matplotlib`](https://matplotlib.org/stable/)), you'll need to install the following packages to run this tutorial:\n",
    "- [`NumPyro`](https://num.pyro.ai/en/stable/getting_started.html)\n",
    "- [`NumPyro-ext`](https://github.com/dfm/numpyro-ext)\n",
    "- [`corner`](https://corner.readthedocs.io/en/latest/)\n",
    "- [`Arviz`](https://python.arviz.org/en/stable/)\n",
    "\n",
    "Let's import the necessary packages and configure the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaxoplanet\n",
    "from jaxoplanet.light_curves import LimbDarkLightCurve\n",
    "from jaxoplanet.orbits import TransitOrbit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpyro\n",
    "import numpyro_ext.distributions, numpyro_ext.optim\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import corner\n",
    "import arviz as az\n",
    "import copy\n",
    "\n",
    "numpyro.set_host_device_count(\n",
    "    2\n",
    ")  # For multi-core parallelism (useful when running multiple MCMC chains in parallel)\n",
    "numpyro.set_platform(\"cpu\")  # For CPU (use \"gpu\" for GPU)\n",
    "jax.config.update(\n",
    "    \"jax_enable_x64\", True\n",
    ")  # For 64-bit precision since JAX defaults to 32-bit\n",
    "\n",
    "\n",
    "print(f\"jaxoplanet.__version__ = {jaxoplanet.__version__}\")\n",
    "print(f\"numpy.__version__ = {np.__version__}\")\n",
    "print(f\"matplotlib.__version__ = {plt.matplotlib.__version__}\")\n",
    "print(f\"numpyro.__version__ = {numpyro.__version__}\")\n",
    "print(f\"numpyro_ext.__version__ = {numpyro_ext.__version__}\")\n",
    "print(f\"jax.__version__ = {jax.__version__}\")\n",
    "print(f\"corner.__version__ = {corner.__version__}\")\n",
    "print(f\"arviz.__version__ = {az.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first compute a simple light curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The light curve calculation requires an orbit object.\n",
    "# We'll use TransitOrbit (similar to SimpleTransitOrbit in the exoplanet package),\n",
    "# which is an orbit parameterized by the observables of a transiting system:\n",
    "# period, speed/duration, time of transit, impact parameter, and radius ratio.\n",
    "orbit = TransitOrbit(\n",
    "    period=3.456, duration=0.12, time_transit=0.0, impact_param=0.0, radius=0.1\n",
    ")  # TODO: Is it actually the radius ratio?\n",
    "\n",
    "\n",
    "# Compute a limb-darkened light curve for this orbit\n",
    "t = np.linspace(-0.1, 0.1, 1000)\n",
    "u = [0.1, 0.06]  # Quadratic limb-darkening coefficients\n",
    "light_curve = LimbDarkLightCurve(u).light_curve(orbit, t)\n",
    "\n",
    "# Plot the light curve\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(t, light_curve, lw=2)\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlim(t.min(), t.max());"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit model in NumPyro\n",
    "\n",
    "We'll construct a transit model using `NumPyro` and fit to some simulated data. `NumPyro` is a probabilistic programming library (PPLs) like `PyMC` that allows us to succinctly build models and perform (gradient-based) inference with them. **NumPyro models must be written in JAX!**\n",
    "\n",
    "\n",
    "Let's start off by choosing the transit properties of our simulated data. These will be the \"true\" values that we would like to recover with our inference. \n",
    "<!-- To make our lives easier let's set the impact parameter $b$ to be 0.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate some data with Gaussian noise\n",
    "random = np.random.default_rng(42)\n",
    "PERIOD = random.uniform(2, 5)  # day\n",
    "T0 = PERIOD * random.uniform()  # day\n",
    "DURATION = 0.5  # day\n",
    "B = 0.5  # impact parameter\n",
    "ROR = 0.08  # planet radius / star radius\n",
    "U = np.array([0.1, 0.06])  # limb darkening coefficients\n",
    "yerr = 5e-4  # flux uncertainty\n",
    "t = np.arange(0, 17, 0.02)  # day\n",
    "\n",
    "\n",
    "orbit = TransitOrbit(\n",
    "    period=PERIOD, duration=DURATION, time_transit=T0, impact_param=B, radius=ROR\n",
    ")\n",
    "y_true = LimbDarkLightCurve(U).light_curve(orbit, t)\n",
    "y = y_true + yerr * random.normal(size=len(t))\n",
    "\n",
    "# Let's see what the light curve looks like\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(t, y_true, \"-k\", lw=1.0, label=\"truth\")\n",
    "plt.plot(t, y, \".k\", ms=2, label=\"data\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.xlim(t.min(), t.max())\n",
    "plt.legend(loc=4);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "Let's define our numpyro model. The syntax for numpyro might be a bit unfamiliar, but here it is.\n",
    "We're sampling the period and duration in log space to constrain it to positive values, and we're also sampling the quadratic limb darkening coefficients using the custom distribution `QuadLDParams` in the `numpyro_ext` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t, yerr, y=None):\n",
    "    # Priors for the parameters we're fitting for\n",
    "\n",
    "    # The time of reference transit\n",
    "    t0 = numpyro.sample(\"t0\", numpyro.distributions.Normal(T0, 1))\n",
    "\n",
    "    # The period\n",
    "    logP = numpyro.sample(\"logP\", numpyro.distributions.Normal(jnp.log(PERIOD), 0.1))\n",
    "    period = numpyro.deterministic(\"period\", jnp.exp(logP))\n",
    "\n",
    "    # The duration\n",
    "    logD = numpyro.sample(\"logD\", numpyro.distributions.Normal(jnp.log(DURATION), 0.1))\n",
    "    duration = numpyro.deterministic(\"duration\", jnp.exp(logD))\n",
    "\n",
    "    # The radius ratio\n",
    "    # logR = numpyro.sample(\"logR\", numpyro.distributions.Normal(jnp.log(ROR), 0.1))\n",
    "    r = numpyro.sample(\"r\", numpyro.distributions.Uniform(0.01, 0.2))\n",
    "    # r = numpyro.deterministic(\"r\", jnp.exp(logR))\n",
    "\n",
    "    # The impact parameter\n",
    "    # b = numpyro.sample(\"b\", numpyro.distributions.Uniform(0, 1.0))\n",
    "    _b = numpyro.sample(\"_b\", numpyro.distributions.Uniform(0, 1.0))\n",
    "    b = numpyro.deterministic(\"b\", _b * (1 + r))\n",
    "\n",
    "    # The limb darkening coefficients\n",
    "    u = numpyro.sample(\"u\", numpyro_ext.distributions.QuadLDParams())\n",
    "\n",
    "    # The orbit and light curve\n",
    "    orbit = TransitOrbit(\n",
    "        period=period, duration=duration, time_transit=t0, impact_param=b, radius=r\n",
    "    )\n",
    "    y_pred = LimbDarkLightCurve(u).light_curve(orbit, t)\n",
    "\n",
    "    # Let's track the light curve\n",
    "    numpyro.deterministic(\"light_curve\", y_pred)\n",
    "\n",
    "    # The likelihood function assuming Gaussian uncertainty\n",
    "    numpyro.sample(\"obs\", numpyro.distributions.Normal(y_pred, yerr), obs=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the priors\n",
    "\n",
    "It can be a good idea to see whether the priors we defined are reasonable by sampling and plotting them. Let's do that now using the `numpyro.infer` submodule's `Predictive` functionality to draw some samples from the priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prior_samples = 3000\n",
    "prior_samples = numpyro.infer.Predictive(model, num_samples=n_prior_samples)(\n",
    "    jax.random.PRNGKey(0), t, yerr\n",
    ")\n",
    "\n",
    "# Let's make it into an arviz InferenceData object.\n",
    "# To do so we'll first need to reshape the samples to be of shape (chains, draws, *shape)\n",
    "converted_prior_samples = {\n",
    "    f\"{p}\": np.expand_dims(prior_samples[p], axis=0) for p in prior_samples\n",
    "}\n",
    "prior_samples_inf_data = az.from_dict(converted_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the corner plot\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "_ = corner.corner(\n",
    "    prior_samples_inf_data,\n",
    "    fig=fig,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    truths=[T0, PERIOD, DURATION, ROR, B, U[0], U[1]],\n",
    "    show_titles=True,\n",
    "    title_kwargs={\"fontsize\": 10},\n",
    "    label_kwargs={\"fontsize\": 12},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These priors seems sensible enough and the true values (blue lines) are within their bounds. Before we start sampling, let's find the maximum a posteriori (MAP) solution. This is a good starting point for the sampling we'll perform later and also a good check to see if things are working.\n",
    "We'll use the `optimize` function defined within the `numpyro_ext` package.\n",
    "\n",
    "We have a choice for the inital value of the optimization. Some potential options include:\n",
    "1. Manually setting them to a specific set of values. This approach might make sense for real data when it's a system that's been studied before and there's a good guess for the parameters. As an example, if we were fitting some follow-up ground-based transit data it might make sense to use the parameters from a Kepler/TESS discovery paper as the initial values.\n",
    "2. The median values of the priors. This might be a good idea when we don't have a good guess for the parameters. Similarly, we could also use the mean values of the priors.\n",
    "\n",
    "Let's do the former and set the initial values to the true values. \n",
    "<!-- Let's do the latter and set the initial values to the median values of the priors. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_param_method = \"true_values\"  # \"prior_median\" or \"true_values\"\n",
    "\n",
    "if init_param_method == \"prior_median\":\n",
    "    print(\"Starting from the prior medians\")\n",
    "    run_optim = numpyro_ext.optim.optimize(\n",
    "        model, init_strategy=numpyro.infer.init_to_median()\n",
    "    )\n",
    "elif init_param_method == \"true_values\":\n",
    "    print(\"Starting from the true values\")\n",
    "    init_params = {\n",
    "        \"t0\": T0,\n",
    "        \"logP\": jnp.log(PERIOD),\n",
    "        \"logD\": jnp.log(DURATION),\n",
    "        \"logR\": jnp.log(ROR),\n",
    "        \"_b\": B / (1 + ROR),\n",
    "        \"u\": U,\n",
    "    }\n",
    "    run_optim = numpyro_ext.optim.optimize(\n",
    "        model,\n",
    "        init_strategy=numpyro.infer.init_to_value(values=init_params),\n",
    "    )\n",
    "\n",
    "opt_params = run_optim(jax.random.PRNGKey(5), t, yerr, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in opt_params.items():\n",
    "    if k in [\"light_curve\", \"obs\", \"_b\"]:\n",
    "        continue\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the MAP model against the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.plot(t, y, \".k\", ms=2, label=\"data\")\n",
    "plt.plot(t, y_true, \"-k\", lw=1.0, label=\"truth\")\n",
    "plt.plot(t, opt_params[\"light_curve\"], \"--C0\", lw=1.0, label=\"MAP model\")\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"relative flux\")\n",
    "plt.legend(fontsize=10, loc=4)\n",
    "plt.xlim(t.min(), t.max());"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Not surprisingly, the MAP model is  a good fit to the data.\n",
    "Let's use these MAP values as the initial values for our sampling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "Let's sample from the posterior defined by this model and data. We'll use the No-U-Turn Sampler (NUTS) algorithm, which is a variant of the Hamiltonian Monte Carlo (HMC) algorithm without the need to hand-tune some of the sampling parameters.\n",
    "\n",
    "This cell takes about 4 minutes to run on my laptop. Dont' worry if you don't see any progress in the first minute or two, it \n",
    "\n",
    "Below, we're setting the ``regularize_mass_matrix`` keyword to ``False``. This is because we realized that the default of setting it to ``True`` causes the sampling to be slower (roughly 6-7 times slower). We're investigating why but it seems (at least for this case) the posteriors are pretty much the same whether you regularize the mass matrix or not. As a side note, not regularizing the mass matrix means we're essentially trading robustness of sampling for speed and may get some divergences. We'll look at these divergences later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = numpyro.infer.MCMC(\n",
    "    numpyro.infer.NUTS(\n",
    "        model,\n",
    "        dense_mass=True,\n",
    "        regularize_mass_matrix=False,\n",
    "        init_strategy=numpyro.infer.init_to_value(values=opt_params),\n",
    "    ),\n",
    "    num_warmup=1000,\n",
    "    num_samples=1000,\n",
    "    num_chains=2,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "sampler.run(jax.random.PRNGKey(1), t, yerr, y=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking our posterior samples\n",
    "\n",
    "We should check the convergence of our sampler. Determining whether a sampler has converged is not trivial and there is a lot of literature on the subject. In our case, we'll attempt to check for convergence by looking at the the Gelman-Rubin $\\hat{R}$ statistic and the bulk effective sample size (ESS) of each parameter. \n",
    "\n",
    "- The [$\\hat{R}$ statistic](https://bookdown.org/rdpeng/advstatcomp/monitoring-convergence.html) is a diagnostic of convergence based on the ratio of the variance between chains to the variance within chains. We would like for it to be close to 1.00 for each parameter. \n",
    "- The [ESS](https://mc-stan.org/docs/2_18/reference-manual/effective-sample-size-section.html) is a measure of the number of independent samples in the chains and is inversely correlated with the autocorrelation in a chain. Larger estimates for the ESS are better as they indicate less autocorrelation in the chains.\n",
    "\n",
    "We can get both of these values using the `summary` function in the `Arviz` package. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_data = az.from_numpyro(sampler)\n",
    "samples = sampler.get_samples()\n",
    "az.summary(inf_data, var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ESS (`ess_bulk`) isn't great for some of the parameters, like the impact parameter $b$, but since the $\\hat{R}$ values are good let's just go ahead with these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's also a method to obtain similar results to `az.summary` but directly\n",
    "# as a method with the MCMC sampler. It also gives us the number of divergences.\n",
    "sampler.print_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a different view of the chains by making some trace plots.\n",
    "The divergences will show up as vertical dashed lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    inf_data,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    backend_kwargs={\"constrained_layout\": True},\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different line styles (not colors!) above indicate the different chains. There's two colors for $u$ since there are two limb-darkening coefficients (i.e., $u_1, u_2$).\n",
    "\n",
    "Let's now make a corner plot of the posterior samples to see the pairwise joint distributions of the parameters and see if there are any correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(\n",
    "    inf_data,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    truths=[T0, PERIOD, DURATION, ROR, B, U[0], U[1]],\n",
    "    show_titles=True,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    "    label_kwargs={\"fontsize\": 15},\n",
    "    title_fmt=\".4f\",\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue lines indicate the true values. \n",
    "\n",
    "The nonlinear correlation between $b$ and $r$ is probably the cause of some of the divergences, but since it's also expected with this parameterization to let's move ahead with it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase plots\n",
    "Let's make the phase plot that is commonly shown in exoplanet papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_t0 = np.median(samples[\"t0\"])\n",
    "inferred_period = np.median(samples[\"period\"])\n",
    "inferred_duration = np.median(samples[\"duration\"])\n",
    "inferred_r = np.median(samples[\"r\"])\n",
    "inferred_b = np.median(samples[\"b\"])\n",
    "inferred_u = np.median(samples[\"u\"], axis=0)\n",
    "\n",
    "orbit = TransitOrbit(\n",
    "    period=inferred_period,\n",
    "    duration=inferred_duration,\n",
    "    time_transit=inferred_t0,\n",
    "    impact_param=inferred_b,\n",
    "    radius=inferred_r,\n",
    ")\n",
    "y_model = LimbDarkLightCurve(inferred_u).light_curve(orbit, t)\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "\n",
    "# Plot the folded data\n",
    "t_fold = (\n",
    "    t - inferred_t0 + 0.5 * inferred_period\n",
    ") % inferred_period - 0.5 * inferred_period\n",
    "ax.errorbar(\n",
    "    t_fold,\n",
    "    y,\n",
    "    yerr=yerr,\n",
    "    marker=\".\",\n",
    "    ls=\"none\",\n",
    "    color=\"k\",\n",
    "    capsize=0,\n",
    "    ms=2,\n",
    "    lw=0.3,\n",
    "    alpha=1,\n",
    "    label=\"data\",\n",
    "    zorder=-100,\n",
    ")\n",
    "\n",
    "# Plot the folded model\n",
    "inds = np.argsort(t_fold)\n",
    "ax.plot(t_fold[inds], y_model[inds], color=\"C1\", lw=1.5, label=\"model\")\n",
    "ax.set_xlabel(\"time since transit [days]\")\n",
    "ax.set_ylabel(\"relative flux\")\n",
    "ax.legend(fontsize=10, loc=4)\n",
    "ax.set_xlim(-inferred_duration, inferred_duration);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Divergences\n",
    "\n",
    "We briefly discussed [divergences](https://mc-stan.org/docs/2_22/reference-manual/divergent-transitions.html) above. Let's take a closer look at them.\n",
    "There's a keyword argument in the `corner` package called `divergences` where if we set it to `True` it will show us the divergences in the corner plot. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(\n",
    "    inf_data,\n",
    "    var_names=[\"t0\", \"period\", \"duration\", \"r\", \"b\", \"u\"],\n",
    "    truths=[T0, PERIOD, DURATION, ROR, B, U[0], U[1]],\n",
    "    divergences=True,\n",
    "    divergences_kwargs={\"color\": \"C1\", \"ms\": 10},\n",
    "    show_titles=True,\n",
    "    quantiles=[0.16, 0.5, 0.84],\n",
    "    title_kwargs={\"fontsize\": 12},\n",
    "    label_kwargs={\"fontsize\": 15},\n",
    "    title_fmt=\".4f\",\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orange dots are the divergences. Based on this plot and the trace plot we made before, it looks like the divergences occur when $b$ and $r$ take on \"large\" values. \n",
    "\n",
    "Let's take a closer look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the divergences in the sampler\n",
    "divergent = sampler.get_extra_fields()[\"diverging\"]\n",
    "\n",
    "b_good = samples[\"b\"][~divergent]\n",
    "r_good = samples[\"r\"][~divergent]\n",
    "b_divergent = samples[\"b\"][divergent]\n",
    "r_divergent = samples[\"r\"][divergent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300)\n",
    "ax.plot(r_good, b_good, \".k\", ms=1, alpha=0.5, label=\"good\")\n",
    "ax.plot(r_divergent, b_divergent, \"xr\", ms=10, alpha=1, label=\"divergent\")\n",
    "ax.set_xlabel(\"radius ratio\")\n",
    "ax.set_ylabel(\"impact parameter\")\n",
    "ax.legend(fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
